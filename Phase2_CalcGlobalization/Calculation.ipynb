{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InternationalityCalculations import CalculateEverything\n",
    "from InternationalityCalculations import DB_joinJournals\n",
    "\n",
    "CalculateEverything('globalization_TOP_NOLIMIT.csv','TOP',excludeMultiDiscipline=False)\n",
    "CalculateEverything('globalization_TOP_BROADLIMIT.csv','TOP',excludeMultiDiscipline='broad')\n",
    "CalculateEverything('globalization_TOP_NARROWLIMIT.csv','TOP',excludeMultiDiscipline='narrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'nolimit':pd.read_csv('DisciplineRobustness/globalization_TOP_NOLIMIT.csv',index_col=['Period','Method','Field','Country']).Internationality,\n",
    "    'broadlimit': pd.read_csv('DisciplineRobustness/globalization_TOP_BROADLIMIT.csv',index_col=['Period','Method','Field','Country']).Internationality,\n",
    "    'narrowlimit': pd.read_csv('DisciplineRobustness/globalization_TOP_NARROWLIMIT.csv',index_col=['Period','Method','Field','Country']).Internationality\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = np.linspace(-1, 1, 200)\n",
    "\n",
    "plt.hist((df.nolimit - df.broadlimit), bins, alpha=0.5, label='Broad disciplines excl.')\n",
    "plt.hist((df.nolimit - df.narrowlimit), bins, alpha=0.5, label='Narrow disciplines excl.')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Deviation of globalization caused by \\n removing journals belonging to multiple disciplines')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = df.groupby(['Field','Method','Period']).rank()\n",
    "\n",
    "(ranks.nolimit - ranks.broadlimit).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devs = pd.DataFrame({'broad':(df.nolimit - df.broadlimit),\n",
    "                     'narrow':(df.nolimit - df.narrowlimit)})\n",
    "devs[(devs.broad >= -0.15) & (devs.broad <= 0.15)].shape[0]/devs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InternationalityData import DB_joinJournals\n",
    "import pandas as pd\n",
    "conn = DB_joinJournals()\n",
    "pd.read_sql_query('''\n",
    "        SELECT c.name as Country, sum(Articles) as Documents\n",
    "        FROM ArticleCountries\n",
    "        inner join countries c on ArticleCountries.FacetID = c.ID\n",
    "        inner join v_issns i on ArticleCountries.ISSNID = i.ID\n",
    "        where\n",
    "            BundleID = {} \n",
    "        {}\n",
    "        group by c.name\n",
    "            AND\n",
    "    i.broadFieldsNum = 1\n",
    "        '''.format(1,'''\n",
    "'''),conn,index_col='Country')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import plotJournalDistsCountries\n",
    "social = plotJournalDistsCountries('top_Social',2017,'euclid',True,False)\n",
    "health = plotJournalDistsCountries('top_Health',2017,'euclid',True,False)\n",
    "life = plotJournalDistsCountries('top_Life',2017,'euclid',True,False)\n",
    "physical = plotJournalDistsCountries('top_Physical',2017,'euclid',True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "idx = pd.IndexSlice\n",
    "dist = pd.DataFrame({\n",
    "    'top_Life':life.stack(),\n",
    "    'top_Health':health.stack(),\n",
    "    'top_Physical':physical.stack(),\n",
    "    'top_Social':social.stack()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = ['Austria','Italy','Belgium','Latvia','Bulgaria','Lithuania','Croatia','Luxembourg','Cyprus','Malta','Czech Republic','Netherlands','Denmark','Poland','Estonia','Portugal','Finland','Romania','France','Slovakia', 'Germany', 'Slovenia', 'Greece','Spain', 'Hungary','Sweden','Ireland']\n",
    "disteu = dist.loc[idx[eu,:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disteu.loc[idx[:,['Q4']],:].unstack(1).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InternationalityData import DB_joinJournals, DB_GetInternationalityData, maxOrMin\n",
    "from InternationalityCalculations import SubsetJournalsByMinDocuments, CalcJournalInternationality\n",
    "import pandas as pd\n",
    "def getJournalDistsCountries(field, period,method,quantiles=4):\n",
    "    d = DB_GetInternationalityData(field, period,True, DB_joinJournals())\n",
    "    d = SubsetJournalsByMinDocuments(d, 30)\n",
    "    #breakpoint()\n",
    "    qu = pd.qcut(CalcJournalInternationality(d, method), quantiles, labels=False)\n",
    "\n",
    "    if maxOrMin[method] == 'min':\n",
    "        qu = quantiles - qu\n",
    "\n",
    "    df = d['countries']\n",
    "    df.loc[:, 'qu'] = qu\n",
    "    df2 = df.groupby('qu').sum() / df.groupby('qu').sum().sum()\n",
    "    df2.index = ['Q{}'.format(x) for x in range(quantiles, 0, -1)]\n",
    "    \n",
    "    #breakpoint()\n",
    "    df2.loc['Documents',:] = df.sum()\n",
    "    df2.loc['Journals',:] = df.apply(lambda x: x[x>0].shape[0])\n",
    "    \n",
    "    df3 = df2.T.reset_index()\n",
    "    df3['period'] = period\n",
    "    df3['field'] = field\n",
    "    df3['method'] = method\n",
    "    return df3.set_index(['Country','field','method','period'])\n",
    "getJournalDistsCountries('top_Life',2017,'euclid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for method in tqdm(['euclid','cosine','GiniSimpson','weightGini','top3','instTOP3','shareEnglish','localShare']):\n",
    "    dfs = []\n",
    "    for yr in range(2005,2018):\n",
    "        for field in ['top_Social','top_Life','top_Health','top_Physical','All']:\n",
    "            dfs.append(getJournalDistsCountries(field,yr,'euclid'))\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    df.to_csv('country_dists_{}.csv'.format(method))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Journal-level Globalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "starting euclid\n\n  0%|          | 0/5 [00:00<?, ?it/s]\n 20%|██        | 1/5 [00:55<03:41, 55.47s/it]\n 40%|████      | 2/5 [02:07<03:01, 60.41s/it]\n 60%|██████    | 3/5 [03:37<02:18, 69.31s/it]\n 80%|████████  | 4/5 [05:03<01:14, 74.46s/it]\n100%|██████████| 5/5 [06:30<00:00, 77.96s/it]starting cosine\n\n  0%|          | 0/5 [00:00<?, ?it/s]\n 20%|██        | 1/5 [01:18<05:13, 78.38s/it]\n 40%|████      | 2/5 [02:34<03:53, 77.77s/it]\n 60%|██████    | 3/5 [03:40<02:28, 74.29s/it]\n 80%|████████  | 4/5 [04:53<01:13, 73.64s/it]\n100%|██████████| 5/5 [06:26<00:00, 79.67s/it]starting GiniSimpson\n\n  0%|          | 0/5 [00:00<?, ?it/s]\n 20%|██        | 1/5 [01:21<05:27, 81.99s/it]\n 40%|████      | 2/5 [02:45<04:07, 82.44s/it]\n 60%|██████    | 3/5 [04:16<02:49, 84.99s/it]\n 80%|████████  | 4/5 [05:50<01:27, 87.69s/it]\n100%|██████████| 5/5 [07:13<00:00, 86.31s/it]starting top3\n\n  0%|          | 0/5 [00:00<?, ?it/s]\n 20%|██        | 1/5 [01:44<06:58, 104.60s/it]\n 40%|████      | 2/5 [03:46<05:29, 109.86s/it]\n 60%|██████    | 3/5 [05:30<03:36, 108.07s/it]\n 80%|████████  | 4/5 [07:35<01:53, 113.11s/it]\n100%|██████████| 5/5 [10:56<00:00, 139.61s/it]starting instTOP3\n\n  0%|          | 0/5 [00:00<?, ?it/s]\n 20%|██        | 1/5 [01:25<05:40, 85.25s/it]\n 40%|████      | 2/5 [02:45<04:10, 83.60s/it]\n 60%|██████    | 3/5 [04:10<02:48, 84.17s/it]\n 80%|████████  | 4/5 [05:07<01:16, 76.00s/it]\n100%|██████████| 5/5 [06:11<00:00, 72.34s/it]starting shareEnglish\n\n  0%|          | 0/5 [00:00<?, ?it/s]\n 20%|██        | 1/5 [01:16<05:06, 76.61s/it]\n 40%|████      | 2/5 [02:29<03:46, 75.48s/it]\n 60%|██████    | 3/5 [03:43<02:29, 74.90s/it]\n 80%|████████  | 4/5 [04:56<01:14, 74.62s/it]\n100%|██████████| 5/5 [06:19<00:00, 76.87s/it]starting localShare\n\n  0%|          | 0/5 [00:00<?, ?it/s]\n 20%|██        | 1/5 [01:22<05:30, 82.67s/it]\n 40%|████      | 2/5 [02:14<03:40, 73.54s/it]\n 60%|██████    | 3/5 [03:00<02:10, 65.22s/it]\n 80%|████████  | 4/5 [04:02<01:04, 64.07s/it]\n100%|██████████| 5/5 [04:59<00:00, 61.95s/it]"
    }
   ],
   "source": [
    "from InternationalityCalculations import DB_joinJournals,SubsetJournalsByMinDocuments,CalcJournalInternationality\n",
    "from InternationalityData import DB_joinJournals,DB_GetInternationalityData\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "def GlobalizationJournalIndicator(field,period,method,conn=None):\n",
    "    if conn is None:\n",
    "        conn = DB_joinJournals()\n",
    "\n",
    "    d = DB_GetInternationalityData(field,period,True,False,conn)\n",
    "    d = SubsetJournalsByMinDocuments(d, 30)\n",
    "\n",
    "    d['method'] = method\n",
    "\n",
    "    if method == 'localShare':\n",
    "        unknownPubCountry = ['1696-2737', '1881-8366', '1604-7982', '1735-4331', '0367-5793', '1738-3102', '1790-8140',\n",
    "                            '1813-8586', '0478-3522', '1732-8705', '2084-3925', '1897-1059']\n",
    "        d['total'] = d['total'].drop(unknownPubCountry, axis='index', errors='ignore')\n",
    "        d['countries'] = d['countries'].drop(unknownPubCountry, axis='index', errors='ignore')\n",
    "\n",
    "    df = CalcJournalInternationality(d,method).to_frame()\n",
    "    df.index = df.index.rename('ISSN')\n",
    "    df.loc[:,'method'] = method\n",
    "    df.loc[:,'field'] = field\n",
    "    df.loc[:,'period'] = period\n",
    "    return df.reset_index().set_index(['method','field','period','ISSN'])\n",
    "\n",
    "db = DB_joinJournals()\n",
    "dfs = []\n",
    "glob = pd.read_csv('data/index.csv').set_index(['country_code','field_code','method_code','period'])['value']\n",
    "flds = [col for col in glob.index.get_level_values('field_code').unique()]\n",
    "flds = ['bro']\n",
    "for method in ['euclid','cosine','GiniSimpson','top3','instTOP3','shareEnglish','localShare']:\n",
    "    print(f'starting {method}')\n",
    "    for yr in [2017]:#list(range(2005,2018)):\n",
    "        for fld in tqdm(['top_Life','top_Health','top_Social','top_Physical','All']):\n",
    "            dfs.append(GlobalizationJournalIndicator(fld,yr,method,db))\n",
    "        pd.concat(dfs).to_csv(f'data/AllJournalIndicators_{method}_{yr}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pd.concat([pd.read_csv(f'data/{f}').rename({0:'globalization'},axis=1) for f in os.listdir('data') if 'AllJournalIndicators' in f]).to_csv('../public_data/globalization_journals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}