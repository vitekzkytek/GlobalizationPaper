{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data and set db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from domestic_journals import *\n",
    "import pandas as pd\n",
    "idx = pd.IndexSlice\n",
    "glob = pd.read_csv('data/index.csv').set_index(['country_code','field_code','method_code','period'])['value']\n",
    "cntrs = pd.read_csv('data/country.csv',index_col='country_code')\n",
    "usedIndicators = ['euclid','cosine','GiniSimpson','weightGini','top3','instTOP3','shareEnglish','localShare']\n",
    "db = DB_joinJournals('sqlite:///c:\\\\Users\\\\OP3202\\\\Documents\\\\Git\\\\GlobalizationPaper\\\\db\\\\180802_1611_AllJournals_ArReCp_2001_2017.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get average growth of documents in the database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totyr = pd.read_sql_query('''\n",
    "SELECT \n",
    "    p.name as year,\n",
    "    sum(Articles) as Documents\n",
    "FROM totalArticles ta\n",
    "inner join periods p on ta.PeriodID = p.ID\n",
    "where year >= 2005\n",
    "group by year\n",
    "''',con=db,index_col='year')\n",
    "from scipy.stats.mstats import gmean\n",
    "gm = gmean(1+totyr.pct_change().Documents.dropna())\n",
    "totyr.Documents.iloc[0]*(gm)**12"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANOVA - countries,disciplines,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "\n\n  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n\n 12%|█▎        | 1/8 [00:04<00:34,  4.91s/it]\u001b[A\u001b[A\n\n 25%|██▌       | 2/8 [00:09<00:29,  4.83s/it]\u001b[A\u001b[A\n\n 38%|███▊      | 3/8 [00:13<00:23,  4.71s/it]\u001b[A\u001b[A\n\n 50%|█████     | 4/8 [00:18<00:18,  4.57s/it]\u001b[A\u001b[A\n\n 62%|██████▎   | 5/8 [00:22<00:13,  4.52s/it]\u001b[A\u001b[A\n\n 75%|███████▌  | 6/8 [00:27<00:09,  4.53s/it]\u001b[A\u001b[A\n\n 88%|████████▊ | 7/8 [00:31<00:04,  4.45s/it]\u001b[A\u001b[A\n\n100%|██████████| 8/8 [00:35<00:00,  4.49s/it]\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>GiniSimpson</th>\n      <th>cosine</th>\n      <th>euclid</th>\n      <th>instTOP3</th>\n      <th>localShare</th>\n      <th>shareEnglish</th>\n      <th>top3</th>\n      <th>weightGini</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">broad</th>\n      <th>C(country_code)</th>\n      <td>37%</td>\n      <td>48%</td>\n      <td>37%</td>\n      <td>44%</td>\n      <td>19%</td>\n      <td>29%</td>\n      <td>32%</td>\n      <td>42%</td>\n    </tr>\n    <tr>\n      <th>C(field_code)</th>\n      <td>20%</td>\n      <td>16%</td>\n      <td>22%</td>\n      <td>17%</td>\n      <td>34%</td>\n      <td>14%</td>\n      <td>25%</td>\n      <td>18%</td>\n    </tr>\n    <tr>\n      <th>C(period)</th>\n      <td>1%</td>\n      <td>0%</td>\n      <td>0%</td>\n      <td>0%</td>\n      <td>2%</td>\n      <td>1%</td>\n      <td>0%</td>\n      <td>1%</td>\n    </tr>\n    <tr>\n      <th>r_squared</th>\n      <td>58%</td>\n      <td>63%</td>\n      <td>59%</td>\n      <td>61%</td>\n      <td>56%</td>\n      <td>44%</td>\n      <td>57%</td>\n      <td>60%</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">narrow</th>\n      <th>C(country_code)</th>\n      <td>55%</td>\n      <td>67%</td>\n      <td>58%</td>\n      <td>64%</td>\n      <td>37%</td>\n      <td>47%</td>\n      <td>53%</td>\n      <td>61%</td>\n    </tr>\n    <tr>\n      <th>C(field_code)</th>\n      <td>14%</td>\n      <td>4%</td>\n      <td>11%</td>\n      <td>4%</td>\n      <td>23%</td>\n      <td>10%</td>\n      <td>9%</td>\n      <td>5%</td>\n    </tr>\n    <tr>\n      <th>C(period)</th>\n      <td>3%</td>\n      <td>0%</td>\n      <td>0%</td>\n      <td>1%</td>\n      <td>4%</td>\n      <td>2%</td>\n      <td>0%</td>\n      <td>2%</td>\n    </tr>\n    <tr>\n      <th>r_squared</th>\n      <td>72%</td>\n      <td>72%</td>\n      <td>69%</td>\n      <td>69%</td>\n      <td>66%</td>\n      <td>60%</td>\n      <td>63%</td>\n      <td>69%</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        GiniSimpson  cosine  euclid  instTOP3  localShare  \\\nbroad  C(country_code)          37%     48%     37%       44%         19%   \n       C(field_code)            20%     16%     22%       17%         34%   \n       C(period)                 1%      0%      0%        0%          2%   \n       r_squared                58%     63%     59%       61%         56%   \nnarrow C(country_code)          55%     67%     58%       64%         37%   \n       C(field_code)            14%      4%     11%        4%         23%   \n       C(period)                 3%      0%      0%        1%          4%   \n       r_squared                72%     72%     69%       69%         66%   \n\n                        shareEnglish  top3  weightGini  \nbroad  C(country_code)           29%   32%         42%  \n       C(field_code)             14%   25%         18%  \n       C(period)                  1%    0%          1%  \n       r_squared                 44%   57%         60%  \nnarrow C(country_code)           47%   53%         61%  \n       C(field_code)             10%    9%          5%  \n       C(period)                  2%    0%          2%  \n       r_squared                 60%   63%         69%  "
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "pd.options.display.float_format = '{:,.0%}'.format\n",
    "from tqdm import tqdm \n",
    "# Calculating effect size\n",
    "def anova_table(df,formula):\n",
    "    model  = ols(formula, df).fit()\n",
    "    aov = sm.stats.anova_lm(model, typ=2)\n",
    "    aov['mean_sq'] = aov[:]['sum_sq']/aov[:]['df']\n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*aov['mean_sq'][-1]))/(sum(aov['sum_sq'])+aov['mean_sq'][-1])\n",
    "    cols = ['sum_sq', 'mean_sq', 'df', 'F', 'PR(>F)', 'eta_sq', 'omega_sq']\n",
    "    aov = aov[cols]\n",
    "    return aov,model\n",
    "\n",
    "ccodes = [col for col in glob.index.get_level_values('country_code').unique() if not col.startswith('_')]\n",
    "flds_narrow = [col for col in glob.index.get_level_values('field_code').unique() if not col.startswith('bot')]\n",
    "flds_broad = [col for col in glob.index.get_level_values('field_code').unique() if not col.startswith('top') or col == 'All']\n",
    "\n",
    "d = {}\n",
    "\n",
    "formula = 'value ~ C(country_code) + \\\n",
    "                   C(field_code) + \\\n",
    "                   C(period)'# + \\\n",
    "                #   C(country_code)*C(field_code)'# + \\\n",
    "                #    C(country_code)*C(period) + \\\n",
    "                #    C(field_code)*C(period) + \\\n",
    "                #    C(field_code)*C(period)*C(country_code)'\n",
    "for method in tqdm(usedIndicators):\n",
    "    df_narrow = glob.loc[idx[ccodes,flds_narrow,method,:]].to_frame().reset_index()\n",
    "    anova_narrow, model_narrow = anova_table(df_narrow,formula)\n",
    "    tbl_narrow = anova_narrow['omega_sq']\n",
    "    tbl_narrow['r_squared'] = model_narrow.rsquared\n",
    "    d[('narrow',method)] = tbl_narrow\n",
    "    #d[('narrow','omega_sq',method)] = anova_table(df_narrow,formula)['omega_sq'].sum()\n",
    "    #d[('narrow','r_sq',method)] = ols(formula,df_narrow).fit().rsquared\n",
    "\n",
    "    df_broad = glob.loc[idx[ccodes,flds_broad,method,:]].to_frame().reset_index()\n",
    "    anova_broad, model_broad = anova_table(df_broad,formula)\n",
    "    tbl_broad = anova_broad['omega_sq']\n",
    "    tbl_broad['r_squared'] = model_broad.rsquared\n",
    "    d[('broad',method)] = tbl_broad\n",
    "\n",
    "#anova_cntr_fld_time = pd.Series(d).unstack()#.stack(0).reorder_levels((1,0)).sort_index()\n",
    "anova_cntr_fld_time = pd.DataFrame(d).stack(0).reorder_levels((1,0)).sort_index()\n",
    "\n",
    "anova_cntr_fld_time.to_clipboard()\n",
    "anova_cntr_fld_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>GiniSimpson</th>\n      <th>cosine</th>\n      <th>euclid</th>\n      <th>instTOP3</th>\n      <th>localShare</th>\n      <th>shareEnglish</th>\n      <th>top3</th>\n      <th>weightGini</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>broad</th>\n      <th>C(country_code)</th>\n      <td>37%</td>\n      <td>48%</td>\n      <td>37%</td>\n      <td>44%</td>\n      <td>19%</td>\n      <td>29%</td>\n      <td>32%</td>\n      <td>42%</td>\n    </tr>\n    <tr>\n      <th>narrow</th>\n      <th>C(country_code)</th>\n      <td>55%</td>\n      <td>67%</td>\n      <td>58%</td>\n      <td>64%</td>\n      <td>37%</td>\n      <td>47%</td>\n      <td>53%</td>\n      <td>61%</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        GiniSimpson  cosine  euclid  instTOP3  localShare  \\\nbroad  C(country_code)          37%     48%     37%       44%         19%   \nnarrow C(country_code)          55%     67%     58%       64%         37%   \n\n                        shareEnglish  top3  weightGini  \nbroad  C(country_code)           29%   32%         42%  \nnarrow C(country_code)           47%   53%         61%  "
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anova_cntr_fld_time.loc[idx[:,'C(country_code)'],:]/anova_cntr_fld_time.loc[idx[:,'C(country_code)'],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "field_code\nAll                                         171\nbot_AgriculturalAndBiological               132\nbot_ArtsHumanities                           76\nbot_BiochemistryGeneticsMolecularBiology    108\nbot_BusinessManagementAccounting             78\nbot_ChemicalEngineering                      77\nbot_Chemistry                                96\nbot_ComputerScience                          88\nbot_DecisionSciences                         55\nbot_Dentistry                                41\nbot_EarthPlanetarySciences                   92\nbot_EconomicsEconometricsFinance             73\nbot_Energy                                   73\nbot_Engineering                             102\nbot_EnvironmentalScience                    111\nbot_General                                   9\nbot_HealthProfessions                        50\nbot_ImmunologyMicrobiology                   90\nbot_Materials                                93\nbot_Mathematics                              91\nbot_Medicine                                153\nbot_Neuroscience                             63\nbot_Nursing                                  58\nbot_PharmacologyToxicologyPharmaceutics      82\nbot_PhysicsAstronomy                         97\nbot_Psychology                               61\nbot_SocialSciences                          115\nbot_Veterinary                               50\ntop_Health                                  155\ntop_Life                                    147\ntop_Physical                                140\ntop_Social                                  125\ndtype: int64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.loc[idx[ccodes,:,'euclid',2017]].reset_index().groupby('field_code').apply(lambda x: len(x.country_code.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = glob.loc[idx[ccodes,'All','euclid',2017]].to_frame().reset_index().drop(['field_code','method_code','period'],axis=1).merge(cntrs,left_on='country_code',right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "dfkm = glob.loc[idx[\n",
    "    [col for col in glob.index.get_level_values('country_code').unique() if not col.startswith('_')],\n",
    "    [col for col in glob.index.get_level_values('field_code').unique() if col.startswith('top')],\n",
    "    'euclid',\n",
    "    2017]].unstack('field_code').dropna()\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kfit=kmeans.fit(dfkm,)\n",
    "dfkm['cluster'] = kmeans.predict(dfkm)\n",
    "import geopandas as gpd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "mapdata = dfkm.reset_index()\n",
    "world = pd.merge(world[['geometry', 'iso_a3']],mapdata,left_on='iso_a3',right_on='country_code')\n",
    "\n",
    "f,ax = plt.subplots(1,figsize=(15,9))\n",
    "world.plot(column='cluster',legend=False,ax=ax,cmap='Accent')\n",
    "ax.set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{c[0]:c[1] for c in zip(dendr['ivl'],dendr['color_list'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage,fcluster\n",
    "from matplotlib import pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "dfh= glob.loc[idx[\n",
    "    [col for col in glob.index.get_level_values('country_code').unique() if not col.startswith('_')],\n",
    "    [col for col in glob.index.get_level_values('field_code').unique() if col.startswith('top')],\n",
    "    'euclid',\n",
    "    2017]].unstack('field_code').dropna()\n",
    "Z = linkage(dfh.values, 'ward')\n",
    "\n",
    "labelList = dfh.index.get_level_values('country_code')\n",
    "max_d = 1\n",
    "fig,axs = plt.subplots(nrows=2,ncols=1,figsize=(20,12),gridspec_kw={'height_ratios': [4, 1]})\n",
    "\n",
    "dendr = dendrogram(Z,\n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=False,\n",
    "            leaf_rotation=45.,  \n",
    "            leaf_font_size=10.,\n",
    "            color_threshold=max_d,\n",
    "            ax=axs[1]\n",
    ")\n",
    "\n",
    "axs[1].axhline(y=max_d, c='k')\n",
    "\n",
    "dfh['cluster'] = fcluster(Z, max_d, criterion='distance')\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.loc[world[world.name == 'France'].iloc[0].name,'iso_a3'] = 'FRA'\n",
    "world.loc[world[world.name == 'Norway'].iloc[0].name,'iso_a3'] = 'NOR'\n",
    "\n",
    "mapdata = dfh.reset_index()\n",
    "world = pd.merge(world[['geometry', 'iso_a3']],mapdata,left_on='iso_a3',right_on='country_code')\n",
    "world['cluster_color'] = world.country_code.map({c[0]:c[1] for c in zip(dendr['ivl'],dendr['color_list'])})\n",
    "world.cluster_color.fillna('w',inplace=True)\n",
    "\n",
    "world.plot(legend=False,ax=axs[0],color=world.cluster_color)\n",
    "axs[0].set_axis_off()\n",
    "#axs[1].set_axis_off()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "c, coph_dists = cophenet(Z, pdist(dfh))\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.DataFrame({\n",
    "    2017:pd.read_sql_query('''\n",
    "            select \n",
    "                c.name as Country,\n",
    "                Sum(Articles) as Articles\n",
    "            from ArticleCountries ac\n",
    "            inner join countries c on c.ID = ac.FacetID\n",
    "            inner join periods p on p.ID = ac.PeriodID\n",
    "            where \n",
    "                p.name = 2017\n",
    "            group by Country\n",
    "            order by Articles DESC\n",
    "        ''',con=db,index_col='Country').Articles,\n",
    "    2005:pd.read_sql_query('''\n",
    "            select \n",
    "                c.name as Country,\n",
    "                Sum(Articles) as Articles\n",
    "            from ArticleCountries ac\n",
    "            inner join countries c on c.ID = ac.FacetID\n",
    "            inner join periods p on p.ID = ac.PeriodID\n",
    "            where \n",
    "                p.name = 2005\n",
    "            group by Country\n",
    "            order by Articles DESC\n",
    "        ''',con=db,index_col='Country').Articles\n",
    "    })\n",
    "\n",
    "countries['imf2003'] = countries.index.map(pd.read_csv('data/country.csv',index_col='full_name').imf2003)\n",
    "countries.groupby('imf2003').sum()[[2005,2017]]/countries.groupby('imf2003').sum()[[2005,2017]].sum()#.T.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntrgrowth = ((countries.loc[:,2017] - countries.loc[:,2005])/countries.loc[:,2005]).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnumber = pd.read_sql_query('''\n",
    "select \n",
    "    ie.broadFieldsNum as broadFieldsNumber,\n",
    "    ie.narrowFieldsNum as narrowFieldsNumber,\n",
    "    Sum(Articles) as Documents from totalArticles ta \n",
    "inner join \n",
    "    (select \n",
    "        *,\n",
    "        (top_Life + top_Social + top_Physical + top_Health) as broadFieldsNum,\n",
    "        (bot_General + bot_AgriculturalAndBiological + bot_ArtsHumanities +\n",
    "        bot_BiochemistryGeneticsMolecularBiology + bot_BusinessManagementAccounting + \n",
    "        bot_ChemicalEngineering + bot_Chemistry + bot_ComputerScience + \n",
    "        bot_DecisionSciences + bot_EarthPlanetarySciences + bot_EconomicsEconometricsFinance +\n",
    "        bot_Energy + bot_Engineering + bot_EnvironmentalScience + bot_ImmunologyMicrobiology +\n",
    "        bot_Materials + bot_Mathematics + bot_Medicine + bot_Neuroscience + bot_Nursing + \n",
    "        bot_PharmacologyToxicologyPharmaceutics + bot_PhysicsAstronomy + bot_Psychology + \n",
    "        bot_SocialSciences + bot_Veterinary + bot_Dentistry + bot_HealthProfessions) as narrowFieldsNum\n",
    "    from issns i\n",
    "    ) ie\n",
    "    ON ie.ID = ta.ISSNID\n",
    "    group by ie.broadFieldsNum,\n",
    "    ie.narrowFieldsNum\n",
    "''',con=db)#.broadFieldsNum.hist(bins=3)\n",
    "fieldshares = pd.DataFrame({\n",
    "    'Broad':fieldnumber.groupby('broadFieldsNumber').Documents.sum()/fieldnumber.groupby('broadFieldsNumber').Documents.sum().sum(),\n",
    "    'Narrow':fieldnumber.groupby('narrowFieldsNumber').Documents.sum()/fieldnumber.groupby('narrowFieldsNumber').Documents.sum().sum()\n",
    "})\n",
    "fieldshares.loc['More',:]=fieldshares.loc[4:,:].sum()\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "fieldshares = fieldshares.loc[[0,1,2,3,'More'],:]*100\n",
    "ax = fieldshares.T.plot.bar(title='Number of disciplines assigned to documents',stacked=True,cmap='gray')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Section"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All indicators show very similar results\n",
    "### Full-Sample correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_full = glob.unstack('method_code').corr()\n",
    "corr_full.loc[usedIndicators,usedIndicators]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Means and stds in all countries, disciplines by Economic status all indicators between 2015 and 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {key:cntrs[key].unique() for key in ['imf2003']}\n",
    "\n",
    "statuses = ['Advanced countries','Developing countries','Transition countries']\n",
    "mdx = pd.MultiIndex.from_product([statuses,['mean','std']],names =['economic_status','stat'])\n",
    "status = pd.DataFrame(index=mdx)\n",
    "key = 'imf2003'\n",
    "for field in ['All','top_Life','top_Physical','top_Social','top_Health']:\n",
    "    for val in statuses:\n",
    "        subdf = glob.loc[idx[cntrs[cntrs[key] == val].index,field,'euclid',[2015,2016,2017]]]\n",
    "        status.loc[(val,'mean'),field] = subdf.mean()\n",
    "        status.loc[(val,'std'),field] = subdf.std()\n",
    "\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,sharey=True,figsize=(10,6))\n",
    "l = ['RUS','CHN']\n",
    "\n",
    "lstyles = ['s-','v-','o-','P-','--']\n",
    "for i in range(2):\n",
    "    a = ax[i]\n",
    "    a.set_ylim((0,1))\n",
    "    a.set_title(l[i])\n",
    "    #breakpoint()\n",
    "    chnrus.xs(l[i]).T.plot(ax=a,style=lstyles,c='gray')#,marker='.',ls='-.',c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "mapdata = pd.DataFrame(glob.loc[idx[:,'All','euclid',2017]])\n",
    "world = pd.merge(world[['geometry', 'iso_a3']],mapdata,left_on='iso_a3',right_index=True)\n",
    "\n",
    "f,ax = plt.subplots(1,figsize=(15,9))\n",
    "#divider = make_axes_locatable(ax)\n",
    "#cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "world.plot(column='value',cmap='gray',legend=False,ax=ax)\n",
    "ax.set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting LocalShares - main logic in data/paper_plots.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals = pd.read_csv('localShares.csv',index_col='Country')\n",
    "locals.localShare.plot(kind='bar',color='gray',figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('paperTables.xlsx')\n",
    "corr_full.loc[usedIndicators,usedIndicators].to_excel(writer,sheet_name='corr_full')\n",
    "status.to_excel(writer,sheet_name='group_means_stds')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output CSVs as an appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.to_csv('appendix/data.csv',header=True)\n",
    "cntrs[cntrs.Type=='country'].imf2003.to_csv('appendix/countries.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfh.dropna().values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}